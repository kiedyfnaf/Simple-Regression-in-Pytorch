# -*- coding: utf-8 -*-
"""simple_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a8h6wu-FwssoQ-W53ihgkFDUjk_NfONs
"""

import torch
import numpy as np
import math
import time
import matplotlib.pyplot as plt
from torch import nn
import torch.optim as optim
import torch.nn.functional as F

#Iterations
PARTS = 1000
#If the loss change is smaller than that break the training loop (for checking if it converged)
CHANGE = 10**(-8)
#How much result is rounded
ROUNDED = 4
#Learning rate
LR = 1e-6

x = torch.linspace(-4, 4, PARTS)
y = x**3 + x**2 + x + 1

exp = torch.tensor([1,2,3])
x_new = x.unsqueeze(-1).pow(exp)

model = torch.nn.Sequential(
    torch.nn.Linear(len(exp),1),
    torch.nn.Flatten(0,1)
    )

loss_fn = torch.nn.MSELoss(reduction='sum')
STOP = False
LAST_LOSS = [1]
loss_history = []
while STOP == False:
  for t in range(PARTS):
    y_pred = model(x_new)
    loss = loss_fn(y_pred, y)
    loss_history.append(loss.item())
    if abs(loss - LAST_LOSS[0]) < CHANGE:
      STOP=True
      break
    else:
      LAST_LOSS[0] = loss
    if t %(PARTS/25) == 0:
      print(t, loss.item())
      if math.isnan(loss.item()):
        LR *= 10
        break
    model.zero_grad()
    loss.backward()
    with torch.no_grad():
      for params in model.parameters():
        params -= LR * params.grad
linear = model[0]

weights = []
for i in range(len(exp)):
  weights.append(round(linear.weight[:,i].item(), ROUNDED))

result = str(round(linear.bias.item(), ROUNDED))
for i in range(len(weights)):
  sign = " + " if weights[i] > 0 else " - "
  result += sign + str(abs(weights[i])) + f"x^{exp[i].item()}"
print(f"Result: {result}")

with torch.no_grad():
    y_pred = model(x_new)

# Plotting the results
plt.figure(figsize=(8, 6))
plt.plot(y, label="True Function", color="blue")
plt.plot(y_pred, label="Model Prediction", color="orange", linestyle="--")
plt.title("Trained Model Function vs True Function")
plt.xlabel("x")
plt.ylabel("y")
plt.legend()
plt.grid()
plt.show()

plt.figure(figsize=(7, 5))
plt.plot(loss_history, label="Loss over Iterations", color="blue")
plt.title("Training Loss")
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.legend()
plt.grid()
plt.show()